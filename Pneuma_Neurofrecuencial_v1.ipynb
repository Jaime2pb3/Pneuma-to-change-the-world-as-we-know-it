{
Celda A — Carga estricta (sin placeholder) + escalado
python
Copiar
Editar
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Columnas reales (fallar si no hay *_Sano y *_AD)
cols_sano = [c for c in df.columns if c.lower().endswith('_sano')]
cols_ad   = [c for c in df.columns if c.lower().endswith('_ad')]
assert len(cols_sano)>0 and len(cols_ad)>0, "❌ Faltan columnas *_Sano o *_AD reales."

X_sano_bank_vec = df[cols_sano].to_numpy(np.float32)
X_ad            = df[cols_ad].to_numpy(np.float32)

# Escalado consistente a [0,1] para que la fractalización no sature
scaler = MinMaxScaler()
X_sano_bank_vec = scaler.fit_transform(X_sano_bank_vec).astype(np.float32)
X_ad            = scaler.transform(X_ad).astype(np.float32)

print("✔️ Shapes:", X_sano_bank_vec.shape, X_ad.shape)
Celda B — Banco ≠ Test (evita optimismo)
python
Copiar
Editar
rng = np.random.default_rng(0)
idx = rng.permutation(len(X_sano_bank_vec))
split = int(0.7*len(idx))
BANK   = X_sano_bank_vec[idx[:split]]   # solo para vecino (kNN)
V_SANO = X_sano_bank_vec[idx[split:]]   # se usa en fidelidad y anomalía

print("BANK:", BANK.shape, "| V_SANO:", V_SANO.shape, "| V_AD:", X_ad.shape)
Celda C — AE (puedes dejar tu entrenamiento igual)
python
Copiar
Editar
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

# AdamW con fallback
try:
    from tensorflow.keras.optimizers import AdamW
    def OPT_ADAMW(lr, wd): return AdamW(learning_rate=lr, weight_decay=wd)
except Exception:
    try:
        from tensorflow.keras.optimizers.experimental import AdamW as AdamWExp
        def OPT_ADAMW(lr, wd): return AdamWExp(learning_rate=lr, weight_decay=wd)
    except Exception:
        def OPT_ADAMW(lr, wd):
            print("⚠️ AdamW no disponible; usando Adam.")
            return Adam(learning_rate=lr)

input_dim = BANK.shape[1]
inp = Input(shape=(input_dim,))
enc = Dense(3, activation='relu')(inp)
dec = Dense(input_dim, activation='sigmoid')(enc)
autoencoder = Model(inp, dec)

cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=300, min_delta=1e-6, restore_best_weights=True)
autoencoder.compile(optimizer=Adam(0.01), loss='mse')
autoencoder.fit(BANK, BANK, epochs=10000, callbacks=[cb], verbose=0)
autoencoder.compile(optimizer=OPT_ADAMW(1e-3, 1e-5), loss='mse')
autoencoder.fit(BANK, BANK, epochs=1000, callbacks=[cb], verbose=0)

print("✅ AE entrenado.")
Celda D — LEVO safe (gating por z-score, mezcla baja, vectorizado)
python
Copiar
Editar
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity

def recon_ae_vec(ae, V):              # V: (N,D)
    return ae.predict(V, verbose=0, batch_size=512)

def recon_denoise_mean(V, mu=None, alpha=0.6):  # baseline simple
    if mu is None: mu = V.mean(axis=0)
    return (alpha*V + (1-alpha)*mu).astype(np.float32)

def fractalizar_safe(v, gain=0.20, freq=3.0):
    # Perturbación suave centrada que mantiene [0,1]
    return np.clip(v + gain*np.sin(np.pi*freq*(v - v.mean())), 0, 1)

def make_recon_levo_fractal_vector_safe(ae, X_bank, cos_thr=0.99, alpha_mix=0.30, z_tau=0.75):
    bank = X_bank.astype(np.float32)
    mu   = bank.mean(axis=0);  sig = bank.std(axis=0) + 1e-6
    nbrs = NearestNeighbors(n_neighbors=1, metric='cosine').fit(bank)

    def recon_fn(V):
        rec = ae.predict(V, verbose=0, batch_size=512)           # 1er pase batch
        cos = cosine_similarity(V, rec).diagonal()
        out = rec.copy()

        hard = cos < cos_thr                                     # casos difíciles
        if hard.any():
            R = rec[hard]
            Z = (R - mu)/sig
            band_mask = np.abs(Z) > z_tau                        # solo bandas raras
            if band_mask.any():
                M = R.copy()
                M[band_mask] = fractalizar_safe(R[band_mask], gain=0.20, freq=3.0)
                mix = (1-alpha_mix)*R + alpha_mix*M
            else:
                mix = R

            rec2 = ae.predict(mix, verbose=0, batch_size=512)    # 2º pase
            cos2 = cosine_similarity(V[hard], rec2).diagonal()
            keep = cos2 >= cos_thr
            out[hard][keep] = rec2[keep]

            if (~keep).any():                                    # vecino sano
                idx = nbrs.kneighbors(rec2[~keep], return_distance=False).ravel()
                out[hard][~keep] = bank[idx]
        return out.astype(np.float32)
    return recon_fn

# Construir métodos con BANK
recon_levo = make_recon_levo_fractal_vector_safe(autoencoder, BANK, cos_thr=0.99, alpha_mix=0.30, z_tau=0.75)
_mu = BANK.mean(axis=0)
methods = {
    'AE':       lambda V: recon_ae_vec(autoencoder, V),
    'AE+LEVO':  recon_levo,
    'Denoise':  lambda V: recon_denoise_mean(V, mu=_mu, alpha=0.6),
}
print("✅ Métodos listos.")
Celda E — Experimento (usa V_SANO y X_ad)
Si ya tienes run_block_vec y evaluate_robustness_vec, usa los tuyos. Te dejo versiones compactas por si acaso.

python
Copiar
Editar
import numpy as np
from sklearn.metrics import roc_auc_score, average_precision_score

# --- si ya existen, omite estas dos funciones ---
def psnr(a,b):
    rngv = (max(a.max(), b.max()) - min(a.min(), b.min())) + 1e-9
    m = np.mean((a-b)**2) + 1e-12
    return 10*np.log10((rngv**2)/m)

def ssim_1d_vec(a,b, K1=0.01, K2=0.03):
    mu_a=a.mean(); mu_b=b.mean()
    va=a.var();   vb=b.var()
    cab=((a-mu_a)*(b-mu_b)).mean()
    C1=(K1**2); C2=(K2**2)
    return float(((2*mu_a*mu_b+C1)*(2*cab+C2))/((mu_a**2+mu_b**2+C1)*(va+vb+C2)))

# ruido; usa los que ya tengas si definiste otros
rng_local = np.random.default_rng(0)
def set_snr(sig, noise, snr_db):
    sp = np.mean(sig**2) + 1e-12
    npow = np.mean(noise**2) + 1e-12
    k = np.sqrt(sp/(npow*10**(snr_db/10)))
    return sig + k*noise
def noise_awgn(shape): return rng_local.standard_normal(shape)
def noise_pink_1f(shape):
    N,D = shape; n=1024; f=np.fft.rfftfreq(n, d=1.0); a=1/np.maximum(f,1/n)
    out=[]
    for _ in range(N):
        spec=(rng_local.standard_normal(len(f))+1j*rng_local.standard_normal(len(f)))*a
        x=np.fft.irfft(spec, n=n).real; x=(x-x.mean())/(x.std()+1e-9)
        out.append(np.interp(np.linspace(0,n-1,D), np.arange(n), x))
    return np.stack(out,0)
def noise_line(shape, freq=60):
    N,D=shape; t=np.linspace(0,1,D,endpoint=False)
    x=(np.sin(2*np.pi*freq*t)+0.5*np.sin(2*np.pi*2*freq*t)+0.25*np.sin(2*np.pi*3*freq*t))
    x=(x-x.mean())/(x.std()+1e-9); return np.tile(x,(N,1))
def add_noise_batch_vec(V, snr_db, kind):
    gen={'awgn':noise_awgn,'pink':noise_pink_1f,'line':noise_line}[kind]
    N,D=V.shape; Nn=gen((N,D))
    return np.vstack([set_snr(V[i], Nn[i], snr_db) for i in range(N)])

def run_block_vec(V_clean, recon_fn, snr_db, noise_kind):
    Vn = add_noise_batch_vec(V_clean, snr_db, noise_kind)
    Vr = recon_fn(Vn)
    return {'psnr': psnr(V_clean, Vr),
            'ssim': ssim_1d_vec(V_clean.ravel(), Vr.ravel())}

def evaluate_robustness_vec(V_sano_train, V_sano_test, V_ad_test, recon_fn, snr_db, noise_kind):
    Vn_sano = add_noise_batch_vec(V_sano_test, snr_db, noise_kind)
    Vn_ad   = add_noise_batch_vec(V_ad_test,   snr_db, noise_kind)
    Vr_sano = recon_fn(Vn_sano)
    Vr_ad   = recon_fn(Vn_ad)
    s_sano  = ((V_sano_test - Vr_sano)**2).mean(axis=1)
    s_ad    = ((V_ad_test   - Vr_ad  )**2).mean(axis=1)
    y = np.concatenate([np.zeros_like(s_sano), np.ones_like(s_ad)])
    scores = np.concatenate([s_sano, s_ad])
    return roc_auc_score(y, scores), average_precision_score(y, scores)

# --- correr ---
NOISES = ['awgn','pink','line']
SNRS   = [20, 10, 0, -5]

rows = []
for nk in NOISES:
    for snr in SNRS:
        for name, fn in methods.items():
            fidel = run_block_vec(V_SANO, fn, snr, nk)
            auc, ap = evaluate_robustness_vec(BANK, V_SANO, X_ad, fn, snr, nk)
            rows.append({'noise': nk, 'snr': snr, 'method': name, 'auc': auc, 'ap': ap, **fidel})

df_results = pd.DataFrame(rows).sort_values(['noise','snr','method'])
df_results.head()
Celda F — Ganancias y veredicto rápido
python
Copiar
Editar
base = df_results[df_results['method']=='AE'][['noise','snr','auc']].rename(columns={'auc':'auc_ae'})
levo = df_results[df_results['method'].str.contains('LEVO')][['noise','snr','auc','method']]
gain = levo.merge(base, on=['noise','snr'])
gain['delta_auc'] = gain['auc'] - gain['auc_ae']
gain_sorted = gain.sort_values(['noise','snr','method']).round(3)
display(gain_sorted)

agg = gain_sorted.groupby('method')['delta_auc'].mean().round(3)
print("ΔAUC promedio:\n", agg)